{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778bc930-4477-4262-9199-2c3d127a4973",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f9695f-f725-4b62-a40a-27f7d62b2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c00ec-6808-4d55-bf3c-27453d6dd9ae",
   "metadata": {},
   "source": [
    "## Declaring input paths and parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f7b225-7ec7-4edb-ab7e-14116645f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    source = r\"C:\\Users\\nisha\\OneDrive\\Desktop\\ML Projects\\Kalkini_Project\\input_videos\\test.mp4\"  # Replace with your video file\n",
    "    output = r\"C:\\Users\\nisha\\OneDrive\\Desktop\\ML Projects\\Kalkini_Project\\output_videos\\test_output_medium_3.mp4\"\n",
    "    weights = r\"C:\\Users\\nisha\\OneDrive\\Desktop\\ML Projects\\Kalkini_Project\\models\\yolov8m.pt\"\n",
    "    conf_thres = 0.5\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "opt = Opt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0103d-8002-47e3-9806-97cf72038bf5",
   "metadata": {},
   "source": [
    "## Loading YOLO and DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aeb24d4-2728-45b0-9796-adafa8a307fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(opt.weights).to(opt.device)\n",
    "tracker = DeepSort(max_age=30, n_init=3, nn_budget=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf4d7f-1855-443d-96d8-e1f42dc94ccc",
   "metadata": {},
   "source": [
    "## Declaring Global Variables and Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b11acb9-edd1-4497-a2c7-6f825645d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(opt.source)\n",
    "frame_width, frame_height = int(cap.get(3)), int(cap.get(4))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set up video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(opt.output, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Track storage\n",
    "id_map = {}  # Map DeepSORT track IDs to unique IDs\n",
    "next_person_id = 1\n",
    "track_history = {}  # Stores movement history\n",
    "rand_color_list = {}  # Assigns random colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8823b-8559-4fbe-9364-969227186803",
   "metadata": {},
   "source": [
    "## Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9343bef5-5dc5-4f23-a64f-8ef913c75248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_people(frame):\n",
    "    \"\"\"Run YOLOv8 on the frame and return detections for persons only.\"\"\"\n",
    "    results = yolo_model(frame, conf=opt.conf_thres)\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            if cls == 0:  # Class '0' is 'person'\n",
    "                detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))\n",
    "    return detections\n",
    "\n",
    "def plot_person_movement(person_ids):\n",
    "    \"\"\"\n",
    "    Visualizes the movement of the given person(s) using stored tracking data.\n",
    "\n",
    "    :param person_ids: A single ID or a list of IDs to visualize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Ensure we handle single ID input\n",
    "    if isinstance(person_ids, int):\n",
    "        person_ids = [person_ids]\n",
    "\n",
    "    for person_id in person_ids:\n",
    "        if person_id in track_history:\n",
    "            coords = track_history[person_id]\n",
    "            xs, ys = zip(*coords)  # Separate x and y coordinates\n",
    "\n",
    "            plt.plot(xs, ys, marker=\"o\", linestyle=\"-\",\n",
    "                     label=f'Person {person_id}', markersize=3)\n",
    "\n",
    "    plt.gca().invert_yaxis()  # Invert Y-axis to match video coordinates\n",
    "    plt.xlabel(\"X Position\")\n",
    "    plt.ylabel(\"Y Position\")\n",
    "    plt.title(\"Movement Path of Tracked Person(s)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def update_tracks(detections, frame):\n",
    "    \"\"\"Update the DeepSORT tracker and assign unique IDs.\"\"\"\n",
    "    global next_person_id\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if track.is_confirmed():\n",
    "            x, y, w, h = map(int, track.to_tlwh())\n",
    "            track_id = track.track_id\n",
    "\n",
    "            # Assign a persistent unique ID\n",
    "            if track_id not in id_map:\n",
    "                id_map[track_id] = next_person_id\n",
    "                next_person_id += 1\n",
    "            unique_id = id_map[track_id]\n",
    "\n",
    "            # Assign color\n",
    "            if unique_id not in rand_color_list:\n",
    "                rand_color_list[unique_id] = (\n",
    "                    random.randint(0, 255),\n",
    "                    random.randint(0, 255),\n",
    "                    random.randint(0, 255),\n",
    "                )\n",
    "            color = rand_color_list[unique_id]\n",
    "\n",
    "            # Draw bounding box and ID\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, f'ID {unique_id}', (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Store movement history\n",
    "            if unique_id not in track_history:\n",
    "                track_history[unique_id] = []\n",
    "            track_history[unique_id].append((x + w // 2, y + h // 2))\n",
    "\n",
    "            # Draw complete movement trail\n",
    "            for i in range(1, len(track_history[unique_id])):\n",
    "                cv2.line(frame, track_history[unique_id][i - 1],\n",
    "                         track_history[unique_id][i], color, 2)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cfbf46-246a-4a29-8a45-3bd3e638cf85",
   "metadata": {},
   "source": [
    "## Main LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6162b1b-d78e-4c1e-b6eb-426afc19db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detections = detect_people(frame)  # YOLO Detection\n",
    "    frame = update_tracks(detections, frame)  # Update DeepSORT Tracker\n",
    "\n",
    "    # Write and display frame\n",
    "    out.write(frame)\n",
    "    cv2.imshow('YOLOv8 + DeepSORT', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f'Output saved to {opt.output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503c063-69b7-499a-a13c-dbcbe29e9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_person_movement(1)  # Visualize person with ID 1\n",
    "plot_person_movement([1, 2, 3])  # Compare movements of IDs 1, 2, and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49876557-9246-462f-a6f6-da0767268069",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "raw",
   "id": "409bb52d-2c8a-4e23-8324-713b6199c389",
   "metadata": {},
   "source": [
    "1. https://www.kaggle.com/datasets/ubaydulloasatullaev/crowd-detection-video/data\n",
    "Initial Static video for checking basic functioning of system. \n",
    "2. https://www.kaggle.com/code/stpeteishii/crowd-video-yolov8-people-number-monitoring/notebook\n",
    "Research Paper , It has sample video as well as YOLOV8x model saved. It also does the part of Trail visualisation.\n",
    "3. https://docs.ultralytics.com/modes/track/\n",
    "Official YOLO Object Tracking documentation\n",
    "4. https://www.kaggle.com/datasets/jonathannield/cctv-action-recognition-dataset\n",
    "CCTV dataset for better insights into project\n",
    "5. https://github.com/jahongir7174/YOLOv8-human\n",
    "Human Detection model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18dc4659-669a-49b1-8627-c50a5464f7f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
